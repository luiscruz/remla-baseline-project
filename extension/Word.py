from typing import Tuple, List, Dict, Iterable
from nltk.corpus import stopwords
import re
from nltk.corpus import wordnet as wn
from nltk.corpus.reader import Synset


STOPWORDS = stopwords.words('english')
POST_TAG_MAP = {
    'NN': [wn.NOUN],
    'JJ': [wn.ADJ, wn.ADJ_SAT],
    'RB': [wn.ADV],
    'VB': [wn.VERB]
}


class Word:

    def __init__(self, value: str, pos_tag: str):
        self.value = value.lower()
        self.pos_tag = Word.convert_pos_tag(pos_tag)
        self.is_stopword: bool = value.lower() in STOPWORDS
        self.variants = self._get_variations()

    @property
    def is_nontrivial(self):
        return not self.is_stopword and not self.pos_tag == '' and not len(self.variants) == 0

    def _get_variations(self) -> Dict[str, int]:
        """
        TODO
        returns dict. key: synonym/hypernym, count: how many times was this suggested by nltk
        """
        if self.is_stopword or self.pos_tag == '':
            return dict()

        synsets = wn.synsets(self.value, pos=self.pos_tag)

        synonyms = self._get_synonyms(synsets)
        hypernyms = self._get_hypernyms(synsets)

        result = Word._count_variants(synonyms, hypernyms)

        return result

    def _get_synonyms(self, synsets: List[Synset]) -> List[str]:
        """
        TODO
        returns list of synonym suggestions
        """
        result: List[str] = []
        for synset in synsets:
            for lemma in synset.lemmas():
                substrings = lemma.name().split('.')
                synonym = substrings[-1]
                synonym_without_underscore = re.sub(r'_', ' ', synonym)
                if self.value != synonym_without_underscore.lower():
                    result.append(synonym_without_underscore)

        return result

    def _get_hypernyms(self, synsets: List[Synset]) -> List[str]:
        """
        TODO
        returns list of hypernym suggestions
        """
        result: List[str] = []
        for synset in synsets:
            for hypernym in synset.hypernyms():
                for lemma in hypernym.lemmas():
                    substrings = lemma.name().split('.')
                    hypernym = substrings[-1]
                    hypernym_without_underscore = re.sub(r'_', ' ', hypernym)
                    if self.value != hypernym_without_underscore.lower():
                        result.append(hypernym_without_underscore)

        return result

    @staticmethod
    def convert_pos_tag(nltk_pos_tag):
        root_tag = nltk_pos_tag[0:2]
        if root_tag in POST_TAG_MAP.keys():
            return POST_TAG_MAP[root_tag]
        else:
            return ''

    @staticmethod
    def _count_variants(*args: Iterable[str]) -> Dict[str, int]:
        """
        TODO
        counts occurences of variation suggestions
        """
        result: Dict[str, int] = dict()

        for variants in args:
            for variant in variants:
                if variant not in result.keys():
                    result[variant] = 1
                else:
                    result[variant] += 1

        return result

    @staticmethod
    def from_tuple(tuple: Tuple[str, str]):
        '''
        Creates an instance of ``Word`` from a (token, part-of-speech tag), as generated by the
        functions ``nltk.pos_tag(tokens)``.

                Parameters:
                        ``tuple`` (``Tuple[str, str]``): A tuple with as the first argument the text
                        token, and as its second argument, the tokens POS tag.

                Returns:
                        an instance of ``Word``
        '''
        return Word(tuple[0], tuple[1])

    def __repr__(self):
        return f"Word(\"{self.value}\", tag: {self.pos_tag}, stopword: {self.is_stopword})"